{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **BitePulse AI - Feature Pipeline**\n",
        "\n"
      ],
      "metadata": {
        "id": "mj52zxVkwyRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction**\n",
        "\n",
        "Our goal in this notebook is to convert labeled meals into model-ready inputs by:\n",
        "\n",
        "* Cutting videos/poses into fixed windows,\n",
        "* Extracting pose & motion features (hand&rarr;mouth distance, wrist speed, elbow angle, etc.), and\n",
        "* Saving tensors + labels to disk for fast training.\n",
        "We'll also add a minimal metrics scaffold (precision/recall for intake events) to quickly sanity-check feature quality."
      ],
      "metadata": {
        "id": "21o_EIOOw28M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data**\n",
        "\n",
        "We'll utilize the data we saved on our google drive from Label prep and task definition notebook - (label_v1):\n",
        "\n",
        "**Our inputs** from labels_v1:\n",
        "\n",
        "* manifest_with_split.parquet: video paths + split\n",
        "* frames_idx.parquet: per-frame labels (label, time_sec, key, split)\n",
        "* segs_idx.parquet: intake segments (start_sec, end_sec, label, key, split)\n",
        "* subject_split.parquet: to avoid subject leakage\n",
        "* true2d_parquet/<key>.parquet: per-frame 2D joints"
      ],
      "metadata": {
        "id": "6NyUoI52x7WT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imports and basic setup**"
      ],
      "metadata": {
        "id": "_HSrSHSR06Iu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7IcUDvAwrpI",
        "outputId": "72d066b2-25f0-4723-81a2-3021fa64509c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, List, Optional\n",
        "import json, re\n",
        "import math\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# let's run below to customize notebook display:\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', 4000)"
      ],
      "metadata": {
        "id": "PS-ROzPq1GJj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paths setup**\n",
        "\n",
        "Here's let's define our exact folders on Drive."
      ],
      "metadata": {
        "id": "38_t0OC01fIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Our paths:\n",
        "ROOT = Path(\"/content/drive/MyDrive/eatsense\")      # project root\n",
        "LABELS = ROOT / \"labels_v1\"                         # label artifacts from previous notebook\n",
        "POSE_PARQ_DIR = ROOT / \"true2d_parquet\"             # per-video 2D pose\n",
        "OUT_WINDOWS = ROOT / \"windows\"                      # output: windowed features & labels\n",
        "\n",
        "# First let's ensure output directory exists:\n",
        "OUT_WINDOWS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# Core config:\n",
        "WIN_SEC = 2.0                 # window length (seconds)\n",
        "STRIDE_SEC = 0.5              # window stride (seconds)\n",
        "FPS_FALLBACK = 15.0           # fallback FPS when not found in map\n",
        "\n",
        "WINDOW_POS_OVERLAP = 0.25     # IoU/overlap with an intake segment to mark window as positive\n",
        "USE_SUMMARY = False           # if True: aggregate per-window stats instead of keeping sequences\n",
        "\n",
        "# Keep in sync with labels_v1/label_config.json:\n",
        "INTAKE_LABELS = {\"Eat it\"}    # which labels count as intake (positive class)\n",
        "\n",
        "\n",
        "# Joint naming:\n",
        "RIGHT_CHAIN = [\"Right-Shoulder\", \"Right-Elbow\", \"Right-Wrist\"]\n",
        "LEFT_CHAIN  = [\"Left-shoulder\", \"Left-Elbow\", \"Left-Wrist\"]\n",
        "HEAD_NAME   = \"head\"\n",
        "\n",
        "ALL_JOINTS = [HEAD_NAME] + RIGHT_CHAIN + LEFT_CHAIN"
      ],
      "metadata": {
        "id": "1mjhFn-R1j3-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **helpers**"
      ],
      "metadata": {
        "id": "mzBe568i2CNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helpers:\n",
        "def load_json(path: Path) -> dict:\n",
        "    if not path.exists():\n",
        "        return {}\n",
        "    with path.open(\"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def save_json(obj: dict, path: Path) -> None:\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with path.open(\"w\") as f:\n",
        "        json.dump(obj, f, indent=2)\n",
        "\n",
        "def get_fps_map(root: Path, fallback: float) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Load per-video FPS dict if available, else return empty dict.\n",
        "    \"\"\"\n",
        "    fps_path = root / \"fps_by_key.json\"\n",
        "    m = load_json(fps_path)\n",
        "    return {str(k): float(v) for k, v in m.items()} if m else {}\n",
        "\n",
        "FPS_BY_KEY: Dict[str, float] = get_fps_map(ROOT, FPS_FALLBACK)\n",
        "\n",
        "def ts_key_from_path(p: str) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Extract the timestamp key (YYYYMMDD_HHMMSS) from a path string.\n",
        "    \"\"\"\n",
        "    m = re.search(r\"(\\d{8}_\\d{6})\", str(p))\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "def fps_for_key(key: str) -> float:\n",
        "    \"\"\"\n",
        "    Get FPS for a given key, falling back when missing.\n",
        "    \"\"\"\n",
        "    return float(FPS_BY_KEY.get(str(key), FPS_FALLBACK))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "58ftq-De2EYt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick sanity print:\n",
        "print(\"ROOT:\", ROOT)\n",
        "print(\"Labels dir:\", LABELS)\n",
        "print(\"Pose parquet dir:\", POSE_PARQ_DIR)\n",
        "print(\"Windows out dir:\", OUT_WINDOWS)\n",
        "print(\"Config -> win:\", WIN_SEC, \"sec | stride:\", STRIDE_SEC, \"sec | fallback FPS:\", FPS_FALLBACK)\n",
        "print(\"Intake labels:\", INTAKE_LABELS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKgsqXuK2OYX",
        "outputId": "0edfc6e9-4976-400f-c011-b36c42206040"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROOT: /content/drive/MyDrive/eatsense\n",
            "Labels dir: /content/drive/MyDrive/eatsense/labels_v1\n",
            "Pose parquet dir: /content/drive/MyDrive/eatsense/true2d_parquet\n",
            "Windows out dir: /content/drive/MyDrive/eatsense/windows\n",
            "Config -> win: 2.0 sec | stride: 0.5 sec | fallback FPS: 15.0\n",
            "Intake labels: {'Eat it'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load label indices & manifest**\n",
        "\n",
        "Here let's pull in the artifacts from labels_v1 that we created earlier \"manifest_with_split.parquet\", \"frames_idx.parquet\", and \"segs_idx.parquet\" (plus subject_split.parquet).\n",
        "\n",
        "This gives us:\n",
        "* The video-to-file map with train/val/test split.\n",
        "* Per-frame labels and times\n",
        "* Merged action segments we'll use to tag windows as positive (intake) or negative."
      ],
      "metadata": {
        "id": "-0Dt1WsQ4hyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required artifacts (under LABELS = ROOT / \"labels_v1\"):\n",
        "MANIFEST_PATH   = LABELS / \"manifest_with_split.parquet\"\n",
        "FRAMES_IDX_PATH = LABELS / \"frames_idx.parquet\"\n",
        "SEGS_IDX_PATH   = LABELS / \"segs_idx.parquet\"          # segment-level labels\n",
        "SUBJ_SPLIT_PATH = LABELS / \"subject_split.parquet\"     # subject-wise split\n",
        "LABEL_CFG_PATH  = LABELS / \"label_config.json\"         # canonical label groups\n",
        "\n",
        "# Load core tables:\n",
        "manifest   = pd.read_parquet(MANIFEST_PATH)[[\"key\", \"rgb\", \"poses_true\", \"split\"]]\n",
        "frames_idx = pd.read_parquet(FRAMES_IDX_PATH)          # cols: key, split, frame, time_sec, label\n",
        "segs_idx   = pd.read_parquet(SEGS_IDX_PATH)            # cols: key, split, start_sec, end_sec, label\n",
        "\n",
        "label_cfg = {}\n",
        "if LABEL_CFG_PATH.exists():\n",
        "    with open(LABEL_CFG_PATH, \"r\") as f:\n",
        "        label_cfg = json.load(f)\n",
        "\n",
        "subjects = None\n",
        "if SUBJ_SPLIT_PATH.exists():\n",
        "    subjects = pd.read_parquet(SUBJ_SPLIT_PATH)\n",
        "\n",
        "# Sanity checks:\n",
        "assert {\"key\", \"rgb\", \"split\"}.issubset(manifest.columns)\n",
        "assert {\"key\", \"frame\", \"time_sec\", \"label\", \"split\"}.issubset(frames_idx.columns)\n",
        "assert {\"key\", \"start_sec\", \"end_sec\", \"label\", \"split\"}.issubset(segs_idx.columns)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5vl_frSl5BVg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intake labels:\n",
        "if \"INTAKE_LABELS\" not in globals():\n",
        "    INTAKE_LABELS = set(label_cfg.get(\"INTAKE\", [\"Eat it\", \"drink\", \"sip\"]))\n",
        "NON_INTAKE_LABELS = set(label_cfg.get(\"NON_INTAKE\", []))\n",
        "\n",
        "# Quick lookups:\n",
        "POSE_PATH_BY_KEY = dict(zip(manifest[\"key\"], manifest[\"poses_true\"]))\n",
        "SPLIT_BY_KEY     = dict(zip(manifest[\"key\"], manifest[\"split\"]))\n",
        "\n",
        "print(\"Loaded:\")\n",
        "print(f\"  manifest:   {manifest.shape}  | splits -> {manifest['split'].value_counts().to_dict()}\")\n",
        "print(f\"  frames_idx: {frames_idx.shape} | splits -> {frames_idx['split'].value_counts().to_dict()}\")\n",
        "print(f\"  segs_idx:   {segs_idx.shape}   | splits -> {segs_idx['split'].value_counts().to_dict()}\")\n",
        "if subjects is not None:\n",
        "    print(f\"  subject_split: {subjects.shape}\")\n",
        "print(f\"INTAKE_LABELS = {sorted(map(str, INTAKE_LABELS))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03NNbjqz6-iJ",
        "outputId": "8180f85c-5dc1-4e27-edf9-20c3a40e0809"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded:\n",
            "  manifest:   (135, 4)  | splits -> {'train': 89, 'val': 25, 'test': 21}\n",
            "  frames_idx: (742887, 5) | splits -> {'train': 471564, 'val': 159546, 'test': 111777}\n",
            "  segs_idx:   (158370, 5)   | splits -> {'train': 100641, 'val': 33233, 'test': 24496}\n",
            "  subject_split: (0, 2)\n",
            "INTAKE_LABELS = ['Eat it']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sliding windows & labels**\n",
        "\n",
        "Here, let's turn our continuous videos into small, fixed-length clips and give each clip a label. This way the Models learn better from uniform clips (e.g., 2 s) than entire videos. basically, for each video we'll slide a window of length WIN_SEC forward by STRIDE_SEC, producing many [start_sec, end_sec] intervals:\n",
        "\n",
        "* Labeling rule: A window is positive (intake) if its temporal IoU with any intake segment (e.g., “Eat it”) is ≥ WINDOW_POS_OVERLAP; otherwise it's negative.\n",
        "\n",
        "* Inputs:\n",
        "\n",
        "  * frames_idx (per-frame times, to get each video's duration)\n",
        "  * segs_idx (ground-truth intake segments with start/end times)\n",
        "  * INTAKE_LABELS, WIN_SEC, STRIDE_SEC, WINDOW_POS_OVERLAP\n",
        "\n",
        "* Output: windows_idx; one row per window with: key, split, win_id, start_sec, end_sec, max_iou, label.\n",
        "\n",
        "This gives us a clean, model-ready index of training clips tied back to each source video."
      ],
      "metadata": {
        "id": "2bJrUZZl773x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def key_durations(frames: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Per-key duration in seconds (max time_sec seen in frames_idx).\n",
        "    \"\"\"\n",
        "    return frames.groupby(\"key\")[\"time_sec\"].max().astype(float)\n",
        "\n",
        "def windows_for_key(total_sec: float,\n",
        "                    win_sec: float,\n",
        "                    stride_sec: float) -> List[Tuple[float, float]]:\n",
        "    \"\"\"\n",
        "    Produce [ (start_sec, end_sec), ... ] for a single video's duration.\n",
        "    \"\"\"\n",
        "    if total_sec <= 0 or win_sec <= 0:\n",
        "        return []\n",
        "    starts = np.arange(0.0, max(total_sec - win_sec, 0) + 1e-9, stride_sec)\n",
        "    return [(float(s), float(min(s + win_sec, total_sec))) for s in starts]\n",
        "\n",
        "def iou_1d(a0: float, a1: float, b0: float, b1: float) -> float:\n",
        "    \"\"\"Intersection-over-Union for 1D segments [a0,a1] and [b0,b1].\"\"\"\n",
        "    inter = max(0.0, min(a1, b1) - max(a0, b0))\n",
        "    union = max(1e-9, (a1 - a0) + (b1 - b0) - inter)\n",
        "    return inter / union\n",
        "\n",
        "def label_windows_for_key(k: str,\n",
        "                          win_pairs: List[Tuple[float, float]],\n",
        "                          intake_segs: pd.DataFrame,\n",
        "                          pos_iou_thresh: float) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    For all windows of one key, compute:\n",
        "      - max IoU to any intake segment\n",
        "      - binary label (1 if max_iou >= pos_iou_thresh, else 0)\n",
        "    Returns (max_iou_vec, label_vec).\n",
        "    \"\"\"\n",
        "    max_iou = np.zeros(len(win_pairs), dtype=float)\n",
        "    if len(intake_segs) == 0:\n",
        "        return max_iou, (max_iou >= pos_iou_thresh).astype(int)\n",
        "\n",
        "    starts = intake_segs[\"start_sec\"].to_numpy(dtype=float)\n",
        "    ends   = intake_segs[\"end_sec\"].to_numpy(dtype=float)\n",
        "\n",
        "    for i, (ws, we) in enumerate(win_pairs):\n",
        "        # quick prune: segments overlapping time span:\n",
        "        lo = (ends   > ws)\n",
        "        hi = (starts < we)\n",
        "        mask = lo & hi\n",
        "        if not mask.any():\n",
        "            continue\n",
        "        ious = [iou_1d(ws, we, float(s), float(e)) for s, e in zip(starts[mask], ends[mask])]\n",
        "        if ious:\n",
        "            max_iou[i] = max(ious)\n",
        "\n",
        "    labels = (max_iou >= pos_iou_thresh).astype(int)\n",
        "    return max_iou, labels\n",
        "\n",
        "def build_window_index(frames_idx: pd.DataFrame,\n",
        "                       segs_idx: pd.DataFrame,\n",
        "                       win_sec: float,\n",
        "                       stride_sec: float,\n",
        "                       pos_iou_thresh: float,\n",
        "                       intake_labels: set) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Create a per-window index across all keys with columns:\n",
        "      key, split, win_id, start_sec, end_sec, max_iou, label\n",
        "    \"\"\"\n",
        "    vid_len = key_durations(frames_idx)   # seconds per key:\n",
        "    # keep only intake segments:\n",
        "    intake = segs_idx[segs_idx[\"label\"].isin(intake_labels)].copy()\n",
        "    intake.sort_values([\"key\", \"start_sec\", \"end_sec\"], inplace=True)\n",
        "\n",
        "    out_rows = []\n",
        "    for k, total_sec in vid_len.items():\n",
        "        # windows for this key:\n",
        "        ws = windows_for_key(total_sec, win_sec, stride_sec)\n",
        "        if not ws:\n",
        "            continue\n",
        "\n",
        "        # all intake segments for this key:\n",
        "        k_segs = intake[intake[\"key\"] == k][[\"start_sec\", \"end_sec\"]]\n",
        "        max_iou, y = label_windows_for_key(k, ws, k_segs, pos_iou_thresh)\n",
        "\n",
        "        split = SPLIT_BY_KEY.get(k, \"train\")\n",
        "        for wid, ((s, e), iou_val, lab) in enumerate(zip(ws, max_iou, y)):\n",
        "            out_rows.append((k, split, wid, s, e, float(iou_val), int(lab)))\n",
        "\n",
        "    win_df = pd.DataFrame(out_rows,\n",
        "                          columns=[\"key\", \"split\", \"win_id\",\n",
        "                                   \"start_sec\", \"end_sec\",\n",
        "                                   \"max_iou\", \"label\"])\n",
        "    return win_df"
      ],
      "metadata": {
        "id": "PRn_80m08z2U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the window index using our config knobs:\n",
        "windows_idx = build_window_index(\n",
        "    frames_idx=frames_idx,\n",
        "    segs_idx=segs_idx,\n",
        "    win_sec=WIN_SEC,\n",
        "    stride_sec=STRIDE_SEC,\n",
        "    pos_iou_thresh=WINDOW_POS_OVERLAP,\n",
        "    intake_labels=INTAKE_LABELS,\n",
        ")"
      ],
      "metadata": {
        "id": "m6Bt7Bp4814K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick sanity: class balance and a few rows:\n",
        "print(\"Windows index:\", windows_idx.shape)\n",
        "print(\"  by split:\", windows_idx[\"split\"].value_counts().to_dict())\n",
        "print(\"  positives:\", int(windows_idx[\"label\"].sum()),\n",
        "      \" | negatives:\", int((1 - windows_idx[\"label\"]).sum()))\n",
        "display(windows_idx.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "trcvwIRm845d",
        "outputId": "dfea165d-5427-423e-a636-66925068fe3e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Windows index: (98582, 7)\n",
            "  by split: {'train': 62568, 'val': 21184, 'test': 14830}\n",
            "  positives: 568  | negatives: 98014\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               key  split  win_id  start_sec  end_sec  max_iou  label\n",
              "0  20210518_230219  train       0        0.0      2.0      0.0      0\n",
              "1  20210518_230219  train       1        0.5      2.5      0.0      0\n",
              "2  20210518_230219  train       2        1.0      3.0      0.0      0\n",
              "3  20210518_230219  train       3        1.5      3.5      0.0      0\n",
              "4  20210518_230219  train       4        2.0      4.0      0.0      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba4d0595-48c3-4a9a-ae1d-575d9f92d4b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>split</th>\n",
              "      <th>win_id</th>\n",
              "      <th>start_sec</th>\n",
              "      <th>end_sec</th>\n",
              "      <th>max_iou</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20210518_230219</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20210518_230219</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20210518_230219</td>\n",
              "      <td>train</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20210518_230219</td>\n",
              "      <td>train</td>\n",
              "      <td>3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20210518_230219</td>\n",
              "      <td>train</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba4d0595-48c3-4a9a-ae1d-575d9f92d4b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba4d0595-48c3-4a9a-ae1d-575d9f92d4b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba4d0595-48c3-4a9a-ae1d-575d9f92d4b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7dc4be97-30b4-4d79-a2c0-e1f225158889\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7dc4be97-30b4-4d79-a2c0-e1f225158889')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7dc4be97-30b4-4d79-a2c0-e1f225158889 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(windows_idx\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"key\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"20210518_230219\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"win_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7905694150420949,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7905694150420949,\n        \"min\": 2.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_iou\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary Highlights:**\n",
        "\n",
        "* Rows: 98,582 windows total\n",
        "* Splits: train/val/test &asymp; 62,568 / 21,184 / 14,830 (mirrors video splits).\n",
        "* Class balance: 568 positives vs 98,014 negatives &rarr; highly imbalanced (&asymp;0.6% positive)."
      ],
      "metadata": {
        "id": "75GvZMIL96E2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pose to window features**\n",
        "\n",
        "Here, let's turn each time window into a compact set of motion features derived from the 2D joints (no pixels yet).\n",
        "\n",
        "For every window (key, start_sec, end_sec) we'll compute things like:\n",
        "\n",
        "* Wrist speed statistics (mean / max) for left & right\n",
        "* Wrist&harr;head distance statistics (min / mean)\n",
        "* Elbow angle statistics (mean / std / min)\n",
        "* Wrist path length (how far the wrist moved in the window)\n",
        "\n",
        "These lightweight features are a great baseline and also useful for debugging the labeling/timing before we try CNN/RNN models on raw frames."
      ],
      "metadata": {
        "id": "tOrxk27M_ErP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "POSE_PATH_BY_KEY: Dict[str, str] = dict(zip(manifest[\"key\"], manifest[\"poses_true\"]))\n",
        "\n",
        "POSE_PARQ_DIR = ROOT / \"true2d_parquet\"\n",
        "OUT_FEATS     = ROOT / \"windows\" / \"pose_feats.parquet\"\n",
        "OUT_FEATS.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Joint naming we expect:\n",
        "RIGHT = [\"right-shoulder\", \"right-elbow\", \"right-wrist\"]\n",
        "LEFT  = [\"left-shoulder\",  \"left-elbow\",  \"left-wrist\"]\n",
        "HEAD  = \"head\"\n",
        "\n",
        "def _find_col(df: pd.DataFrame, base: str, suffix: str) -> str:\n",
        "    \"\"\"Locate a column by lowercase name match, tolerant to capitalization like 'Left-shoulder'.\"\"\"\n",
        "    want = f\"{base.lower()}_{suffix}\"\n",
        "    for c in df.columns:\n",
        "        if c.lower() == want:\n",
        "            return c\n",
        "    raise KeyError(f\"column '{want}' not found in pose dataframe\")\n",
        "\n",
        "def _speed(x: np.ndarray, y: np.ndarray, t: np.ndarray) -> np.ndarray:\n",
        "    vx = np.gradient(x, t, edge_order=1)\n",
        "    vy = np.gradient(y, t, edge_order=1)\n",
        "    return np.hypot(vx, vy)\n",
        "\n",
        "def _angle(ax, ay, bx, by, cx, cy) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Elbow angle ABC in degrees, where B is the elbow.\n",
        "    A=shoulder, B=elbow, C=wrist.\n",
        "    \"\"\"\n",
        "    v1x, v1y = ax - bx, ay - by\n",
        "    v2x, v2y = cx - bx, cy - by\n",
        "    # normalize:\n",
        "    n1 = np.hypot(v1x, v1y) + 1e-6\n",
        "    n2 = np.hypot(v2x, v2y) + 1e-6\n",
        "    dot = (v1x*v2x + v1y*v2y) / (n1*n2)\n",
        "    dot = np.clip(dot, -1.0, 1.0)\n",
        "    return np.degrees(np.arccos(dot))\n",
        "\n",
        "def load_pose_df_for_key(key: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load per-frame pose for a video:\n",
        "      1) try fast parquet:  ROOT/true2d_parquet/{key}.parquet\n",
        "      2) fall back to CSV path from manifest['poses_true'] for this key\n",
        "    Expected columns after load: 'frame','time_sec' and f'{joint}_x','{joint}_y'.\n",
        "    \"\"\"\n",
        "    parq = POSE_PARQ_DIR / f\"{key}.parquet\"\n",
        "    if parq.exists():\n",
        "        df = pd.read_parquet(parq)\n",
        "        return df\n",
        "\n",
        "    # Fallback to CSV (slower) - parse \"(x, y)\" strings:\n",
        "    csv_path = Path(POSE_PATH_BY_KEY[key])\n",
        "    df = pd.read_csv(csv_path).copy()\n",
        "    assert \"image_id\" in df.columns, \"Expected 'image_id' column\"\n",
        "    df.rename(columns={\"image_id\": \"frame\"}, inplace=True)\n",
        "\n",
        "    # If FPS mapping exists on disk, use it; else assume fallback\n",
        "    fps_map_path = ROOT / \"fps_by_key.json\"\n",
        "    fps = 15.0\n",
        "    if fps_map_path.exists():\n",
        "        try:\n",
        "\n",
        "            with open(fps_map_path, \"r\") as f:\n",
        "                m = json.load(f)\n",
        "            # key like '20210518_230219':\n",
        "            ts_key = key  # our key is already the timestamp token\n",
        "            if ts_key in m:\n",
        "                fps = float(m[ts_key])\n",
        "        except Exception:\n",
        "            pass\n",
        "    df[\"time_sec\"] = df[\"frame\"] / float(fps)\n",
        "\n",
        "    # Split \"(x, y)\" columns into numeric:\n",
        "    import re\n",
        "    pat = re.compile(r\"\\(?\\s*([-+]?\\d*\\.?\\d+(?:e[-+]?\\d+)?)\\s*[, ]\\s*([-+]?\\d*\\.?\\d+(?:e[-+]?\\d+)?)\\s*\\)?\", re.I)\n",
        "    meta = {\"path\",\"imgName\",\"frame\",\"date\",\"time\",\"Action\"}\n",
        "    joints = [c for c in df.columns if c not in meta]\n",
        "    for j in joints:\n",
        "        xy = df[j].map(lambda s: pat.match(str(s)).groups() if pd.notna(s) and pat.match(str(s)) else (np.nan, np.nan))\n",
        "        df[f\"{j}_x\"] = pd.to_numeric([p[0] for p in xy], errors=\"coerce\")\n",
        "        df[f\"{j}_y\"] = pd.to_numeric([p[1] for p in xy], errors=\"coerce\")\n",
        "    keep = [\"frame\",\"time_sec\"] + [f\"{j}_x\" for j in joints] + [f\"{j}_y\" for j in joints]\n",
        "    return df[keep].reset_index(drop=True)\n",
        "\n",
        "def slice_window(df: pd.DataFrame, start: float, end: float) -> pd.DataFrame:\n",
        "    m = (df[\"time_sec\"] >= start) & (df[\"time_sec\"] < end)\n",
        "    return df.loc[m]\n",
        "\n",
        "def wrist_path_len(x: np.ndarray, y: np.ndarray) -> float:\n",
        "    if len(x) < 2:\n",
        "        return 0.0\n",
        "    return float(np.hypot(np.diff(x), np.diff(y)).sum())\n",
        "\n",
        "def summarize_window(dfw: pd.DataFrame) -> Dict[str, float]:\n",
        "    \"\"\"Compute features for one window slice of the pose dataframe.\"\"\"\n",
        "    if dfw.empty:\n",
        "        return {   # consistent NaNs so downstream can impute:\n",
        "            \"rw_speed_mean\": np.nan, \"rw_speed_max\": np.nan, \"rw_head_min\": np.nan, \"rw_path\": 0.0,\n",
        "            \"lw_speed_mean\": np.nan, \"lw_speed_max\": np.nan, \"lw_head_min\": np.nan, \"lw_path\": 0.0,\n",
        "            \"re_angle_mean\": np.nan, \"re_angle_std\": np.nan,\n",
        "            \"le_angle_mean\": np.nan, \"le_angle_std\": np.nan,\n",
        "        }\n",
        "\n",
        "    t  = dfw[\"time_sec\"].to_numpy()\n",
        "\n",
        "    # Resolve column names robustly:\n",
        "    rx = dfw[_find_col(dfw, \"Right-Wrist\", \"x\")].to_numpy()\n",
        "    ry = dfw[_find_col(dfw, \"Right-Wrist\", \"y\")].to_numpy()\n",
        "    lx = dfw[_find_col(dfw, \"Left-Wrist\", \"x\")].to_numpy()\n",
        "    ly = dfw[_find_col(dfw, \"Left-Wrist\", \"y\")].to_numpy()\n",
        "\n",
        "    hx = dfw[_find_col(dfw, HEAD, \"x\")].to_numpy()\n",
        "    hy = dfw[_find_col(dfw, HEAD, \"y\")].to_numpy()\n",
        "\n",
        "    rsx = dfw[_find_col(dfw, \"Right-Shoulder\", \"x\")].to_numpy()\n",
        "    rsy = dfw[_find_col(dfw, \"Right-Shoulder\", \"y\")].to_numpy()\n",
        "    rex = dfw[_find_col(dfw, \"Right-Elbow\", \"x\")].to_numpy()\n",
        "    rey = dfw[_find_col(dfw, \"Right-Elbow\", \"y\")].to_numpy()\n",
        "\n",
        "    lsx = dfw[_find_col(dfw, \"Left-Shoulder\", \"x\")].to_numpy()\n",
        "    lsy = dfw[_find_col(dfw, \"Left-Shoulder\", \"y\")].to_numpy()\n",
        "    lex = dfw[_find_col(dfw, \"Left-Elbow\", \"x\")].to_numpy()\n",
        "    ley = dfw[_find_col(dfw, \"Left-Elbow\", \"y\")].to_numpy()\n",
        "\n",
        "    # Speeds:\n",
        "    r_speed = _speed(rx, ry, t)\n",
        "    l_speed = _speed(lx, ly, t)\n",
        "\n",
        "    # Distances to head:\n",
        "    rw_head = np.hypot(rx - hx, ry - hy)\n",
        "    lw_head = np.hypot(lx - hx, ly - hy)\n",
        "\n",
        "    # Elbow angles:\n",
        "    r_ang = _angle(rsx, rsy, rex, rey, rx, ry)\n",
        "    l_ang = _angle(lsx, lsy, lex, ley, lx, ly)\n",
        "\n",
        "    return {\n",
        "        \"rw_speed_mean\": float(np.nanmean(r_speed)),\n",
        "        \"rw_speed_max\":  float(np.nanmax(r_speed)),\n",
        "        \"rw_head_min\":   float(np.nanmin(rw_head)),\n",
        "        \"rw_path\":       wrist_path_len(rx, ry),\n",
        "\n",
        "        \"lw_speed_mean\": float(np.nanmean(l_speed)),\n",
        "        \"lw_speed_max\":  float(np.nanmax(l_speed)),\n",
        "        \"lw_head_min\":   float(np.nanmin(lw_head)),\n",
        "        \"lw_path\":       wrist_path_len(lx, ly),\n",
        "\n",
        "        \"re_angle_mean\": float(np.nanmean(r_ang)),\n",
        "        \"re_angle_std\":  float(np.nanstd(r_ang)),\n",
        "        \"le_angle_mean\": float(np.nanmean(l_ang)),\n",
        "        \"le_angle_std\":  float(np.nanstd(l_ang)),\n",
        "    }\n",
        "\n",
        "# Extract features for all windows:\n",
        "def build_pose_features(windows: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    For each key, load pose once, then compute features across that key's windows.\n",
        "    Returns a DataFrame aligned 1:1 with input `windows`.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for key, g in windows.groupby(\"key\", sort=False):\n",
        "        try:\n",
        "            pose_df = load_pose_df_for_key(key)\n",
        "        except Exception as e:\n",
        "            print(f\"[warn] failed to load pose for {key}: {e}\")\n",
        "            # Keep placeholder rows (NaNs) so downstream alignment remains intact:\n",
        "            for _, r in g.iterrows():\n",
        "                rows.append({\n",
        "                    \"key\": key, \"split\": r[\"split\"], \"win_id\": r[\"win_id\"],\n",
        "                    \"start_sec\": r[\"start_sec\"], \"end_sec\": r[\"end_sec\"], \"label\": r[\"label\"],\n",
        "                    **summarize_window(pd.DataFrame())\n",
        "                })\n",
        "            continue\n",
        "\n",
        "        for _, r in g.iterrows():\n",
        "            dfw = slice_window(pose_df, r[\"start_sec\"], r[\"end_sec\"])\n",
        "            feats = summarize_window(dfw)\n",
        "            rows.append({\n",
        "                \"key\": key, \"split\": r[\"split\"], \"win_id\": r[\"win_id\"],\n",
        "                \"start_sec\": r[\"start_sec\"], \"end_sec\": r[\"end_sec\"],\n",
        "                \"label\": r[\"label\"],     # 1 if positive (by IoU), else 0\n",
        "                **feats,\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AfzZkrS2_ih5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pose_feats = build_pose_features(windows_idx)\n",
        "print(\"pose_feats:\", pose_feats.shape)\n",
        "display(pose_feats.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "P12kAimS_9D0",
        "outputId": "c73f516e-f95a-48b1-d951-d016d250cc99"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pose_feats: (98582, 18)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               key  split  win_id  start_sec  end_sec  label  rw_speed_mean  \\\n",
              "0  20210518_230219  train       0        0.0      2.0      0     145.005528   \n",
              "1  20210518_230219  train       1        0.5      2.5      0     144.750844   \n",
              "2  20210518_230219  train       2        1.0      3.0      0     115.429775   \n",
              "3  20210518_230219  train       3        1.5      3.5      0      70.348694   \n",
              "4  20210518_230219  train       4        2.0      4.0      0      59.101835   \n",
              "\n",
              "   rw_speed_max  rw_head_min     rw_path  lw_speed_mean  lw_speed_max  \\\n",
              "0    292.955069    16.572304  388.575546      93.775873    240.865456   \n",
              "1    292.955069    16.572304  395.191243      86.067394    240.865456   \n",
              "2    292.955069    16.572304  326.245907      84.059480    240.865456   \n",
              "3    261.323483    44.639644  161.334968      65.090198    173.324211   \n",
              "4    261.323483    77.260761  120.857773      55.453864    173.324211   \n",
              "\n",
              "   lw_head_min     lw_path  re_angle_mean  re_angle_std  le_angle_mean  \\\n",
              "0    20.674800  254.556086     156.609365     26.183085     159.404531   \n",
              "1    20.674800  242.444187     154.726599     25.178434     156.092829   \n",
              "2    20.674800  238.720912     143.522549     28.808757     146.182834   \n",
              "3    70.185487  156.761878     132.174230     32.609472     132.567564   \n",
              "4    67.433284  111.393292     121.100324     32.854782     118.182391   \n",
              "\n",
              "   le_angle_std  \n",
              "0     13.165441  \n",
              "1     12.925139  \n",
              "2     17.691644  \n",
              "3     22.362200  \n",
              "4     26.003087  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c39f76ae-ae34-49cf-9261-34f675cee31d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>split</th>\n",
              "      <th>win_id</th>\n",
              "      <th>start_sec</th>\n",
              "      <th>end_sec</th>\n",
              "      <th>label</th>\n",
              "      <th>rw_speed_mean</th>\n",
              "      <th>rw_speed_max</th>\n",
              "      <th>rw_head_min</th>\n",
              "      <th>rw_path</th>\n",
              "      <th>lw_speed_mean</th>\n",
              "      <th>lw_speed_max</th>\n",
              "      <th>lw_head_min</th>\n",
              "      <th>lw_path</th>\n",
              "      <th>re_angle_mean</th>\n",
              "      <th>re_angle_std</th>\n",
              "      <th>le_angle_mean</th>\n",
              "      <th>le_angle_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20210518_230219</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>145.005528</td>\n",
              "      <td>292.955069</td>\n",
              "      <td>16.572304</td>\n",
              "      <td>388.575546</td>\n",
              "      <td>93.775873</td>\n",
              "      <td>240.865456</td>\n",
              "      <td>20.674800</td>\n",
              "      <td>254.556086</td>\n",
              "      <td>156.609365</td>\n",
              "      <td>26.183085</td>\n",
              "      <td>159.404531</td>\n",
              "      <td>13.165441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20210518_230219</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0</td>\n",
              "      <td>144.750844</td>\n",
              "      <td>292.955069</td>\n",
              "      <td>16.572304</td>\n",
              "      <td>395.191243</td>\n",
              "      <td>86.067394</td>\n",
              "      <td>240.865456</td>\n",
              "      <td>20.674800</td>\n",
              "      <td>242.444187</td>\n",
              "      <td>154.726599</td>\n",
              "      <td>25.178434</td>\n",
              "      <td>156.092829</td>\n",
              "      <td>12.925139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20210518_230219</td>\n",
              "      <td>train</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>115.429775</td>\n",
              "      <td>292.955069</td>\n",
              "      <td>16.572304</td>\n",
              "      <td>326.245907</td>\n",
              "      <td>84.059480</td>\n",
              "      <td>240.865456</td>\n",
              "      <td>20.674800</td>\n",
              "      <td>238.720912</td>\n",
              "      <td>143.522549</td>\n",
              "      <td>28.808757</td>\n",
              "      <td>146.182834</td>\n",
              "      <td>17.691644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20210518_230219</td>\n",
              "      <td>train</td>\n",
              "      <td>3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>70.348694</td>\n",
              "      <td>261.323483</td>\n",
              "      <td>44.639644</td>\n",
              "      <td>161.334968</td>\n",
              "      <td>65.090198</td>\n",
              "      <td>173.324211</td>\n",
              "      <td>70.185487</td>\n",
              "      <td>156.761878</td>\n",
              "      <td>132.174230</td>\n",
              "      <td>32.609472</td>\n",
              "      <td>132.567564</td>\n",
              "      <td>22.362200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20210518_230219</td>\n",
              "      <td>train</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>59.101835</td>\n",
              "      <td>261.323483</td>\n",
              "      <td>77.260761</td>\n",
              "      <td>120.857773</td>\n",
              "      <td>55.453864</td>\n",
              "      <td>173.324211</td>\n",
              "      <td>67.433284</td>\n",
              "      <td>111.393292</td>\n",
              "      <td>121.100324</td>\n",
              "      <td>32.854782</td>\n",
              "      <td>118.182391</td>\n",
              "      <td>26.003087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c39f76ae-ae34-49cf-9261-34f675cee31d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c39f76ae-ae34-49cf-9261-34f675cee31d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c39f76ae-ae34-49cf-9261-34f675cee31d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3aaf67a7-769f-4c56-9493-b4a612136395\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3aaf67a7-769f-4c56-9493-b4a612136395')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3aaf67a7-769f-4c56-9493-b4a612136395 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(pose_feats\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"key\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"20210518_230219\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"win_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7905694150420949,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7905694150420949,\n        \"min\": 2.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rw_speed_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40.55284680868913,\n        \"min\": 59.10183528139727,\n        \"max\": 145.00552829018767,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          144.75084389296774\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rw_speed_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.32533336771692,\n        \"min\": 261.3234830323828,\n        \"max\": 292.95506937170114,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          261.3234830323828\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rw_head_min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26.90420997287923,\n        \"min\": 16.572304338709174,\n        \"max\": 77.26076104637659,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          16.572304338709174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rw_path\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 129.02697675796847,\n        \"min\": 120.85777254200542,\n        \"max\": 395.1912431818693,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          395.1912431818693\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lw_speed_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.96482050562836,\n        \"min\": 55.45386375428794,\n        \"max\": 93.77587305298204,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          86.06739412528454\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lw_speed_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.993863499649514,\n        \"min\": 173.32421136702382,\n        \"max\": 240.86545646044064,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          173.32421136702382\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lw_head_min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26.382348697412805,\n        \"min\": 20.674799932865145,\n        \"max\": 70.18548657992622,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          20.674799932865145\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lw_path\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.23539989577235,\n        \"min\": 111.39329167331904,\n        \"max\": 254.55608605665088,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          242.44418653305277\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"re_angle_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.086112161958045,\n        \"min\": 121.10032439180249,\n        \"max\": 156.60936481472726,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          154.72659853125575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"re_angle_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.5490511254824337,\n        \"min\": 25.178434247606084,\n        \"max\": 32.854781954677016,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          25.178434247606084\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"le_angle_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.132497547567432,\n        \"min\": 118.18239081866604,\n        \"max\": 159.40453146861384,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          156.09282903753862\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"le_angle_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.731014349222636,\n        \"min\": 12.925138836565326,\n        \"max\": 26.00308732956914,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          12.925138836565326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save once built:\n",
        "pose_feats.to_parquet(OUT_FEATS, index=False)\n",
        "print(f\"Saved pose features -> {OUT_FEATS}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsQPETvQABdf",
        "outputId": "6e793af6-8742-420b-99f1-a6141b530446"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved pose features -> /content/drive/MyDrive/eatsense/windows/pose_feats.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pack model-ready arrays (X, y) and exports**\n",
        "\n",
        "Now that we have pose_feats (one row per window with metadata + numeric features), let's:\n",
        "\n",
        "* Select the numeric feature columns,\n",
        "* Split into train/val/test using the split column,\n",
        "* Standardize features using stats from the train set only,\n",
        "* Export light-weight files we can feed into a baseline model quickly (.npz with X, y, and meta).\n",
        "\n",
        "This keeps the \"feature pipeline\" self-contained and makes training notebooks tiny."
      ],
      "metadata": {
        "id": "DZO2dPYKC3XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EXPORT_DIR = ROOT / \"windows\"\n",
        "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# First, let's identify feature columns:\n",
        "META_COLS = {\"key\",\"split\",\"win_id\",\"start_sec\",\"end_sec\",\"label\"}\n",
        "all_cols  = list(pose_feats.columns)\n",
        "FEAT_COLS = [c for c in all_cols if c not in META_COLS]\n",
        "\n",
        "# Small sanity:\n",
        "assert len(FEAT_COLS) > 0, \"No feature columns detected!\""
      ],
      "metadata": {
        "id": "YhlCzqowDLpb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split:\n",
        "df_train = pose_feats.query(\"split == 'train'\").reset_index(drop=True)\n",
        "df_val   = pose_feats.query(\"split == 'val'\").reset_index(drop=True)\n",
        "df_test  = pose_feats.query(\"split == 'test'\").reset_index(drop=True)\n",
        "\n",
        "print(\"Rows:\", {k: len(v) for k, v in\n",
        "               {\"train\": df_train, \"val\": df_val, \"test\": df_test}.items()})\n",
        "print(\"Class balance (positives):\",\n",
        "      {\"train\": int(df_train[\"label\"].sum()),\n",
        "       \"val\":   int(df_val[\"label\"].sum()),\n",
        "       \"test\":  int(df_test[\"label\"].sum())})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dEvyYmHDYzu",
        "outputId": "656aad90-33e3-40c6-8957-4e0af3c1da0d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: {'train': 62568, 'val': 21184, 'test': 14830}\n",
            "Class balance (positives): {'train': 422, 'val': 57, 'test': 89}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize using TRAIN only:\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(df_train[FEAT_COLS].values.astype(np.float32))\n",
        "X_val   = scaler.transform(df_val[FEAT_COLS].values.astype(np.float32))\n",
        "X_test  = scaler.transform(df_test[FEAT_COLS].values.astype(np.float32))\n",
        "\n",
        "y_train = df_train[\"label\"].values.astype(np.int64)\n",
        "y_val   = df_val[\"label\"].values.astype(np.int64)\n",
        "y_test  = df_test[\"label\"].values.astype(np.int64)\n",
        "\n",
        "# Keep slim metadata for debugging/eval later:\n",
        "meta_train = df_train[[\"key\",\"win_id\",\"start_sec\",\"end_sec\"]].copy()\n",
        "meta_val   = df_val[[\"key\",\"win_id\",\"start_sec\",\"end_sec\"]].copy()\n",
        "meta_test  = df_test[[\"key\",\"win_id\",\"start_sec\",\"end_sec\"]].copy()"
      ],
      "metadata": {
        "id": "4DiFUiToDe3b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save exports:\n",
        "np.savez_compressed(EXPORT_DIR / \"Xy_train_pose.npz\",\n",
        "                    X=X_train, y=y_train,\n",
        "                    keys=meta_train[\"key\"].to_numpy(),\n",
        "                    win_id=meta_train[\"win_id\"].to_numpy(),\n",
        "                    start=meta_train[\"start_sec\"].to_numpy(),\n",
        "                    end=meta_train[\"end_sec\"].to_numpy(),\n",
        "                    feat_cols=np.array(FEAT_COLS))\n",
        "\n",
        "np.savez_compressed(EXPORT_DIR / \"Xy_val_pose.npz\",\n",
        "                    X=X_val, y=y_val,\n",
        "                    keys=meta_val[\"key\"].to_numpy(),\n",
        "                    win_id=meta_val[\"win_id\"].to_numpy(),\n",
        "                    start=meta_val[\"start_sec\"].to_numpy(),\n",
        "                    end=meta_val[\"end_sec\"].to_numpy(),\n",
        "                    feat_cols=np.array(FEAT_COLS))\n",
        "\n",
        "np.savez_compressed(EXPORT_DIR / \"Xy_test_pose.npz\",\n",
        "                    X=X_test, y=y_test,\n",
        "                    keys=meta_test[\"key\"].to_numpy(),\n",
        "                    win_id=meta_test[\"win_id\"].to_numpy(),\n",
        "                    start=meta_test[\"start_sec\"].to_numpy(),\n",
        "                    end=meta_test[\"end_sec\"].to_numpy(),\n",
        "                    feat_cols=np.array(FEAT_COLS))\n",
        "\n",
        "# Save the scaler for reuse (so eval uses the exact same normalization):\n",
        "joblib.dump(scaler, EXPORT_DIR / \"scaler_pose.joblib\")\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(\" -\", EXPORT_DIR / \"Xy_train_pose.npz\")\n",
        "print(\" -\", EXPORT_DIR / \"Xy_val_pose.npz\")\n",
        "print(\" -\", EXPORT_DIR / \"Xy_test_pose.npz\")\n",
        "print(\" -\", EXPORT_DIR / \"scaler_pose.joblib\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX8A3XgYDj5c",
        "outputId": "8e0934b2-bde9-4e03-df46-68977b737085"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved:\n",
            " - /content/drive/MyDrive/eatsense/windows/Xy_train_pose.npz\n",
            " - /content/drive/MyDrive/eatsense/windows/Xy_val_pose.npz\n",
            " - /content/drive/MyDrive/eatsense/windows/Xy_test_pose.npz\n",
            " - /content/drive/MyDrive/eatsense/windows/scaler_pose.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary Highlights:**\n",
        "\n",
        "* .npz is tiny, loadable in one line, and framework-agnostic.\n",
        "* Keeping feat_cols inside ensures feature order stays consistent.\n",
        "* Saving the scaler prevents train/val/test leakage and makes downstream evaluation reproducible."
      ],
      "metadata": {
        "id": "znkjFoQ_Dqvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Metrics scaffold**\n",
        "\n",
        "Here, let's hook up a simple, fast baseline to verify the feature pipeline end-to-end:\n",
        "\n",
        "* loads the saved NPZs (Xy_train_pose.npz, Xy_val_pose.npz, Xy_test_pose.npz)\n",
        "* train a class-weighted neural network baseline (MLP for flat features or GRU head for sequences).\n",
        "* finds a decision threshold that maximizes F1 on the validation set\n",
        "* reports precision / recall / F1, ROC AUC, PR AUC, and a confusion matrix on val and test"
      ],
      "metadata": {
        "id": "I2N7TSt4Hebo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The block below trains a tiny PyTorch model on the NPZ features we saved earlier.\n",
        "It auto-detects the feature shape:\n",
        "\n",
        "* 2D (N, F) &rarr; a small MLP with dropout\n",
        "* 3D (N, T, D) &rarr; a GRU followed by a linear head (uses the last hidden state)\n",
        "\n",
        "It uses `BCEWithLogitsLoss` with class weighting, chooses a threshold that maximizes F1 on the validation set, and reports metrics on val and test."
      ],
      "metadata": {
        "id": "AEobVvgUIrKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import (\n",
        "    precision_recall_curve, average_precision_score, roc_auc_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")"
      ],
      "metadata": {
        "id": "NT6odDKPHzmF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "ROOT = Path(\"/content/drive/MyDrive/eatsense\")\n",
        "OUT_WINDOWS = ROOT / \"windows\"\n",
        "\n",
        "# load NPZs:\n",
        "def _load_npz(p: Path):\n",
        "    z = np.load(p, allow_pickle=True)\n",
        "    X = z[\"X\"]\n",
        "    y = z[\"y\"].astype(np.float32)\n",
        "    return X, y\n",
        "\n",
        "Xtr, ytr = _load_npz(OUT_WINDOWS / \"Xy_train_pose.npz\")\n",
        "Xva, yva = _load_npz(OUT_WINDOWS / \"Xy_val_pose.npz\")\n",
        "Xte, yte = _load_npz(OUT_WINDOWS / \"Xy_test_pose.npz\")\n",
        "\n",
        "print(\"train\", Xtr.shape, \"val\", Xva.shape, \"test\", Xte.shape)\n",
        "\n",
        "# standardize (fit on train only):\n",
        "def zscore_fit(X):\n",
        "    if X.ndim == 2:\n",
        "        mu = X.mean(0, keepdims=True)\n",
        "        sd = X.std(0, keepdims=True) + 1e-8\n",
        "    else:  # (N, T, D) -> stats over N,T for each D\n",
        "        mu = X.reshape(-1, X.shape[-1]).mean(0, keepdims=True)\n",
        "        sd = X.reshape(-1, X.shape[-1]).std(0, keepdims=True) + 1e-8\n",
        "    return mu, sd\n",
        "\n",
        "def zscore_apply(X, mu, sd):\n",
        "    if X.ndim == 2:\n",
        "        return (X - mu) / sd\n",
        "    else:\n",
        "        return (X - mu.reshape(1,1,-1)) / sd.reshape(1,1,-1)\n",
        "\n",
        "mu, sd = zscore_fit(Xtr)\n",
        "Xtr = zscore_apply(Xtr, mu, sd).astype(np.float32)\n",
        "Xva = zscore_apply(Xva, mu, sd).astype(np.float32)\n",
        "Xte = zscore_apply(Xte, mu, sd).astype(np.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3pSkcXbI6oO",
        "outputId": "dee1bedc-d759-4f04-bb35-f153225a72aa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train (62568, 12) val (21184, 12) test (14830, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# datasets:\n",
        "class NPZDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X)\n",
        "        self.y = torch.from_numpy(y).float()\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "train_ds = NPZDataset(Xtr, ytr)\n",
        "val_ds   = NPZDataset(Xva, yva)\n",
        "test_ds  = NPZDataset(Xte, yte)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=512, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=1024, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=1024, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "5FBtOgwhJG2o"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model:\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=256, p=0.2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p),\n",
        "            nn.Linear(hidden, hidden//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p),\n",
        "            nn.Linear(hidden//2, 1),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(-1)\n",
        "\n",
        "class GRUHead(nn.Module):\n",
        "    def __init__(self, feat_dim, hid=128, layers=1, p=0.2, bidir=False):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=feat_dim, hidden_size=hid,\n",
        "            num_layers=layers, batch_first=True, bidirectional=bidir\n",
        "        )\n",
        "        out_dim = hid * (2 if bidir else 1)\n",
        "        self.head = nn.Sequential(nn.Dropout(p), nn.Linear(out_dim, 1))\n",
        "    def forward(self, x):          # x: (B, T, D)\n",
        "        out, h = self.gru(x)       # last hidden state:\n",
        "        if isinstance(h, tuple):   # (for LSTM compatibility)\n",
        "            h = h[0]\n",
        "        h_last = h[-1]             # (B, H)\n",
        "        return self.head(h_last).squeeze(-1)\n",
        "\n",
        "def make_model(X_sample):\n",
        "    if X_sample.ndim == 2:\n",
        "        return MLP(in_dim=X_sample.shape[1])\n",
        "    elif X_sample.ndim == 3:\n",
        "        return GRUHead(feat_dim=X_sample.shape[-1], hid=128, layers=1, p=0.3, bidir=False)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported X shape: {X_sample.shape}\")\n",
        "\n",
        "model = make_model(Xtr)\n",
        "model.to(DEVICE)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuTupx6FJNDG",
        "outputId": "40eaa289-0982-46ce-82f0-fecef1eea037"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=12, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.2, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss, optimizer, class weighting:\n",
        "pos = float(ytr.sum())\n",
        "neg = float(len(ytr) - pos)\n",
        "pos_weight = torch.tensor(neg / (pos + 1e-8), device=DEVICE)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "#training / evaluation helpers:\n",
        "@torch.no_grad()\n",
        "def predict_proba(loader):\n",
        "    model.eval()\n",
        "    probs = []\n",
        "    for xb, _ in loader:\n",
        "        xb = xb.to(DEVICE, non_blocking=True)\n",
        "        if xb.ndim == 2:\n",
        "            logit = model(xb)\n",
        "        else:\n",
        "            logit = model(xb)\n",
        "        probs.append(torch.sigmoid(logit).cpu().numpy())\n",
        "    return np.concatenate(probs)\n",
        "\n",
        "def train_epoch():\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "    for xb, yb in train_loader:\n",
        "        xb = xb.to(DEVICE, non_blocking=True)\n",
        "        yb = yb.to(DEVICE, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total += float(loss.item()) * len(yb)\n",
        "    scheduler.step()\n",
        "    return total / len(train_ds)\n",
        "\n",
        "def pick_thr_max_f1(y_true, y_prob):\n",
        "    p, r, th = precision_recall_curve(y_true, y_prob)\n",
        "    f1 = 2*p*r/(p+r+1e-12)\n",
        "    i = np.nanargmax(f1[:-1])\n",
        "    return float(th[i]), float(f1[i])\n",
        "\n",
        "def eval_split(y_true, y_prob, thr):\n",
        "    y_hat = (y_prob >= thr).astype(int)\n",
        "    out = {\n",
        "        \"roc_auc\": roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan,\n",
        "        \"pr_auc\": average_precision_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan,\n",
        "        \"precision\": precision_score(y_true, y_hat, zero_division=0),\n",
        "        \"recall\": recall_score(y_true, y_hat, zero_division=0),\n",
        "        \"f1\": f1_score(y_true, y_hat, zero_division=0),\n",
        "        \"cm\": confusion_matrix(y_true, y_hat),\n",
        "        \"report\": classification_report(y_true, y_hat, digits=3, zero_division=0),\n",
        "    }\n",
        "    return out"
      ],
      "metadata": {
        "id": "Gg4XVuCPJ-1u"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train loop with simple early stopping:\n",
        "best_val = -np.inf\n",
        "best_state = None\n",
        "patience = 5\n",
        "pat_count = 0\n",
        "EPOCHS = 25\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    tr_loss = train_epoch()\n",
        "    # monitor val F1 at optimal thr each epoch:\n",
        "    p_va = predict_proba(val_loader)\n",
        "    thr, f1_val = pick_thr_max_f1(yva, p_va)\n",
        "    print(f\"epoch {epoch:02d} | train loss {tr_loss:.4f} | val F1* {f1_val:.3f} @ thr {thr:.3f}\")\n",
        "    if f1_val > best_val + 1e-4:\n",
        "        best_val = f1_val\n",
        "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "        pat_count = 0\n",
        "    else:\n",
        "        pat_count += 1\n",
        "        if pat_count >= patience:\n",
        "            print(\"Early stopping.\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMzNzPhXKKR2",
        "outputId": "4588f48f-bc77-4e1d-d654-7ba40b5b2f29"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01 | train loss 0.8149 | val F1* 0.420 @ thr 0.911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 02 | train loss 0.3583 | val F1* 0.414 @ thr 0.955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 03 | train loss 0.2624 | val F1* 0.407 @ thr 0.975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 04 | train loss 0.2502 | val F1* 0.406 @ thr 0.962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 05 | train loss 0.2028 | val F1* 0.395 @ thr 0.967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 06 | train loss 0.1997 | val F1* 0.414 @ thr 0.970\n",
            "Early stopping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load best weights:\n",
        "if best_state is not None:\n",
        "    model.load_state_dict(best_state)"
      ],
      "metadata": {
        "id": "0q5AjHE_KajZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final evaluation:\n",
        "p_va = predict_proba(val_loader)\n",
        "thr, f1_val = pick_thr_max_f1(yva, p_va)\n",
        "va_metrics = eval_split(yva, p_va, thr)\n",
        "\n",
        "p_te = predict_proba(test_loader)\n",
        "te_metrics = eval_split(yte, p_te, thr)\n",
        "\n",
        "print(\"\\n=== Deep baseline (PyTorch) ===\")\n",
        "print(f\"Chosen threshold (max F1 on val): {thr:.3f} | best val F1*: {f1_val:.3f}\")\n",
        "print(f\"[VAL]  ROC AUC: {va_metrics['roc_auc']:.3f}  PR AUC: {va_metrics['pr_auc']:.3f}  \"\n",
        "      f\"P: {va_metrics['precision']:.3f}  R: {va_metrics['recall']:.3f}  F1: {va_metrics['f1']:.3f}\")\n",
        "print(va_metrics[\"cm\"])\n",
        "print(va_metrics[\"report\"])\n",
        "\n",
        "print(f\"[TEST] ROC AUC: {te_metrics['roc_auc']:.3f}  PR AUC: {te_metrics['pr_auc']:.3f}  \"\n",
        "      f\"P: {te_metrics['precision']:.3f}  R: {te_metrics['recall']:.3f}  F1: {te_metrics['f1']:.3f}\")\n",
        "print(te_metrics[\"cm\"])\n",
        "print(te_metrics[\"report\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVMzFYP3KdKG",
        "outputId": "4d23c2d2-42ab-43ea-8416-3e789f33f17f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Deep baseline (PyTorch) ===\n",
            "Chosen threshold (max F1 on val): 0.911 | best val F1*: 0.420\n",
            "[VAL]  ROC AUC: 0.992  PR AUC: 0.360  P: 0.403  R: 0.439  F1: 0.420\n",
            "[[21090    37]\n",
            " [   32    25]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.998     0.998     0.998     21127\n",
            "         1.0      0.403     0.439     0.420        57\n",
            "\n",
            "    accuracy                          0.997     21184\n",
            "   macro avg      0.701     0.718     0.709     21184\n",
            "weighted avg      0.997     0.997     0.997     21184\n",
            "\n",
            "[TEST] ROC AUC: 0.895  PR AUC: 0.640  P: 0.981  R: 0.573  F1: 0.723\n",
            "[[14740     1]\n",
            " [   38    51]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.997     1.000     0.999     14741\n",
            "         1.0      0.981     0.573     0.723        89\n",
            "\n",
            "    accuracy                          0.997     14830\n",
            "   macro avg      0.989     0.786     0.861     14830\n",
            "weighted avg      0.997     0.997     0.997     14830\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary Highlights:**\n",
        "\n",
        "This is a baseline sanity check to prove the pipeline, windows, labels, and training loop work end-to-end. It's doing its job: metrics make sense, confusion matrices look sane, and there's no obvious leakage:\n",
        "\n",
        "* Works end-to-end: windows &rarr; features &rarr; training &rarr; eval are all wired correctly.\n",
        "\n",
        "* Val vs. Test gap: test does better (higher PR AUC/F1). Likely due to:\n",
        "  * Slightly higher positive rate in test, and/or\n",
        "  * Test clips that are easier (cleaner movements). This isn't a red flag—just a reminder that PR AUC is sensitive to prevalence and difficulty.\n",
        "* Thresholding: we're using a val-optimized threshold and applying it to test (good).\n",
        "* No leakage signals: very low FP rates and reasonable recall given the scarcity of positives.\n",
        "\n"
      ],
      "metadata": {
        "id": "SXWPIBuOUF10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save Artifacts**"
      ],
      "metadata": {
        "id": "RYvEvjGdV3Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = OUT_WINDOWS / \"artifacts\"; MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "torch.save(model.state_dict(), MODEL_DIR / \"baseline_pose_gru.pt\")\n",
        "np.savez(MODEL_DIR / \"zscore_pose.npz\", mu=mu, sd=sd)\n"
      ],
      "metadata": {
        "id": "kYFbj6YvV7Y8"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}